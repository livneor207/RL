# -*- coding: utf-8 -*-
"""RL_Final_Project_2022.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1q6DlXWB8D2sD0TN6T1Ax8UiQk85mq_Gr

## link to summary file:
https://www.overleaf.com/project/62a8262246ccc31212711e3a

* env documentation:
 * https://highway-env.readthedocs.io/en/latest

## example for DQN
1. Car Race
  * https://github.com/andywu0913/OpenAI-GYM-CarRacing-DQN
2. A3C -  Asynchronous Methods for Deep Reinforcement Learning 
  * https://github.com/tensorpack/tensorpack/tree/master/examples/A3C-Gym
3. Curiosity-driven Exploration by Self-supervised Prediction
  * https://github.com/pathak22/noreward-rl

4. many RL Algorithem GIT:
  * https://github.com/Rafael1s/Deep-Reinforcement-Learning-Algorithms

5. course code examples 
  * https://github.com/ShangtongZhang/reinforcement-learning-an-introduction

* rewards:
 * 
 * 

* add stochestic 
  * 0.85/0.15

* classes:
 * agent class
 * simulation class
 * 

examples :
  * https://highway-env.readthedocs.io/en/latest/quickstart.html#examples-on-google-colab

# Final Project - Reinforcements Learning 
Hello dear students,<br> this is the template notebook. Please click on the "File" tab and then on "Save a copy into drive".

---
<br>

### Name and ID:
Student 1: Or Livne  - 203972922
<br>
Student 2: Oz Sharlin - 200705754
<br><br>
# Goodluck!
"""

!pip install highway-env
!pip install git+https://github.com/DLR-RM/stable-baselines3
!pip install tensorboardx gym pyvirtualdisplay
!apt-get install -y xvfb python-opengl ffmpeg
!git clone https://github.com/eleurent/highway-env.git 2> /dev/null
!git clone https://github.com/avivg7/highway-config.git

# Commented out IPython magic to ensure Python compatibility.
import gym
import highway_env
import sys
sys.path.insert(0, '/content/highway-env/scripts/')
from tqdm.notebook import trange
from utils import record_videos, show_videos
import numpy as np
from gym import logger as gymlogger
from gym.wrappers import Monitor
from gym.utils import seeding
from gym import error, spaces, utils
gymlogger.set_level(40) # error only
import io
import base64
import os
import random
import matplotlib.pyplot as plt
import math
import glob
from pyvirtualdisplay import Display
from IPython.display import HTML
from IPython import display as ipythondisplay
import pygame
import json
import ast
# %load_ext tensorboard
# %matplotlib inline

env = gym.make("highway-fast-v0")

# env.action_space
# # env.compute_reward(achieved_goal = 5, desired_goal = 4)
# env.episode_id
# env.metadata
# # env.render
# env.action_space.sample()
ACTIONS_ALL = {
        0: 'LANE_LEFT',
        1: 'IDLE',
        2: 'LANE_RIGHT',
        3: 'FASTER',
        4: 'SLOWER'
    }

#Manual control
  # env.configure({"controlled_vehicles": 2})  # Two controlled vehicles
  # env.configure({"vehicles_count": 1})  # A single other vehicle, for the sake of visualisation

"""
examples to:
Observations
  1. Grayscale Image
  2. Occupancy grid
Actions
  1.Discrete Meta-Actions
  2. Manual control
Rewards
  1. Eq
"""

"""## Display utils
The cell below contains the video display configuration. No need to make changes here.
"""

# Commented out IPython magic to ensure Python compatibility.
display = Display(visible=0, size=(1400, 900))
display.start()

if type(os.environ.get("DISPLAY")) is not str or len(os.environ.get("DISPLAY"))==0:
    !bash ../xvfb start
#     %env DISPLAY=:1

"""
Utility functions to enable video recording of gym environment 
and displaying it.
To enable video, just do "env = wrap_env(env)""
"""

def show_video():
  mp4list = glob.glob('video/*.mp4')
  if len(mp4list) > 0:
    mp4 = mp4list[0]
    video = io.open(mp4, 'r+b').read()
    encoded = base64.b64encode(video)
    ipythondisplay.display(HTML(data='''<video alt="test" autoplay 
                loop controls style="height: 400px;">
                <source src="data:video/mp4;base64,{0}" type="video/mp4" />
             </video>'''.format(encoded.decode('ascii'))))
  else: 
    print("Could not find video")
    

def wrap_env(env):
  env = Monitor(env, './video', force=True)
  return env

"""## EX1 - Highway-Env - Grayscale Image - Easy

"""

#=============== DO NOT DELETE ===============
file = open('/content/highway-config/config_ex1.txt', 'r')
contents = file.read()
config1 = ast.literal_eval(contents)
file.close()
# ============================================

env = gym.make("highway-fast-v0")
env.configure(config1)

obs = env.reset()
for j in range(10):
    obs, _, _, _ = env.step(0)

    _, axes = plt.subplots(ncols=4, figsize=(12, 5))
    for i, ax in enumerate(axes.flat):
        ax.imshow(obs[i, ...].T, cmap=plt.get_cmap('gray'))
    

env = wrap_env(env)
env.reset()
done = False
iter = 0

while (iter < 10) or not done:
  if done:
    break
  iter +=1
  action = env.action_space.sample()
  observation, reward, done, _ = env.step(action)
  screen = env.render(mode='rgb_array')
  plt.imshow(screen)
  print(f'iteration: {iter}, action: {action}, reward: {reward}, done: {done}')

env.close()
show_video()

"""# EX2 - Highway-Env - Grayscale Image - Medium"""

#=============== DO NOT DELETE ===============
file = open('/content/highway-config/config_ex2.txt', 'r')
contents = file.read()
config2 = ast.literal_eval(contents)
file.close()
# ============================================

env = gym.make("highway-fast-v0")
env.configure(config2)

obs = env.reset()
for j in range(10):
    sam_act = env.action_space.sample()
    obs, _, _, _ = env.step(sam_act)

    _, axes = plt.subplots(ncols=4, figsize=(12, 5))
    for i, ax in enumerate(axes.flat):
        ax.imshow(obs[i, ...].T, cmap=plt.get_cmap('gray'))
    
env = wrap_env(env)
env.reset()
done = False
iter = 0
while (iter < 40) or not done:
  if done:
    break
  iter +=1
  action = env.action_space.sample()
  observation, reward, done, _ = env.step(action)
  screen = env.render(mode='rgb_array')
  plt.imshow(screen)
  print(f'iteration: {iter}, action: {action}, reward: {reward}, done: {done}')

"""### Play video"""

env.close()
show_video()

"""# Ex3 - Super Highway Agent"""

#=============== DO NOT DELETE ===============
file = open('/content/highway-config/config_ex3.txt', 'r')
contents = file.read()
config3 = ast.literal_eval(contents)
file.close()
# ============================================

"""### Ex3 - Highway-Env"""

env = gym.make("highway-fast-v0")
env.configure(config3) 

env = wrap_env(env)
env.reset()
done = False
iter = 0
while (iter < 10) or not done:
  if done:
    break
  iter +=1
  action = env.action_space.sample()
  observation, reward, done, _ = env.step(action)
  screen = env.render(mode='rgb_array')
  plt.imshow(screen)
  print(f'iteration: {iter}, action: {action}, reward: {reward}, done: {done}')

"""### Play video"""

env.close()
show_video()

"""### Ex3 - Merge-Env"""

env = gym.make("merge-v0")
env.configure(config3) 

env = wrap_env(env)
env.reset()
done = False
iter = 0

while (iter < 10) or not done:
  if done:
    break
  iter +=1
  action = env.action_space.sample()
  observation, reward, done, _ = env.step(action)
  screen = env.render(mode='rgb_array')
  plt.imshow(screen)
  print(f'iteration: {iter}, action: {action}, reward: {reward}, done: {done}')

"""### Play video

"""

env.close()
show_video()

"""### Ex3 - Roundabout-Env"""

env = gym.make("roundabout-v0")
env.configure(config3) 
env = wrap_env(env)
env.reset()
done = False
iter = 0
while (iter < 10) or not done:
  if done:
    break
  iter +=1
  action = env.action_space.sample()
  observation, reward, done, _ = env.step(action)
  screen = env.render(mode='rgb_array')
  plt.imshow(screen)
  print(f'iteration: {iter}, action: {action}, reward: {reward}, done: {done}')

"""### Play video"""

env.close()
show_video()